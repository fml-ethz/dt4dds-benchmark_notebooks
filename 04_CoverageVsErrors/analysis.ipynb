{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dt4dds_benchmark\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_dropout = dt4dds_benchmark.analysis.Dataset.combine(*[dt4dds_benchmark.pipelines.HDF5Manager(f'./data/dropout/{s}.hdf5').get_data() for s in (\n",
    "    'aeon_high',\n",
    "    'aeon_low',\n",
    "    'aeon_medium',\n",
    "    'fountain_high',\n",
    "    'fountain_low',\n",
    "    'fountain_medium',\n",
    "    'goldman_default',\n",
    "    'rs_high',\n",
    "    'rs_low',\n",
    "    'rs_medium',\n",
    "    'hedges_low',\n",
    "    'hedges_medium',\n",
    "    'yinyang_default',\n",
    ")])\n",
    "data_rate = dt4dds_benchmark.analysis.Dataset.combine(*[dt4dds_benchmark.pipelines.HDF5Manager(f'./data/rate/{s}.hdf5').get_data() for s in (\n",
    "    'aeon_high',\n",
    "    'aeon_low',\n",
    "    'aeon_medium',\n",
    "    'fountain_high',\n",
    "    'fountain_low',\n",
    "    'fountain_medium',\n",
    "    'goldman_default',\n",
    "    'rs_high',\n",
    "    'rs_low',\n",
    "    'rs_medium',\n",
    "    'hedges_low',\n",
    "    'hedges_medium',\n",
    "    'yinyang_default',\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap_type = {'DNAAeon': '#3182bd', 'DNAFountain': '#31a354', 'DNARS': '#e6550d', 'HEDGES': '#756bb1', 'YinYang': '#636363', 'Goldman': '#de2d26'}\n",
    "\n",
    "colormap_name = {\n",
    "    'DNAAeon-High': '#08519c', 'DNAAeon-Medium': '#3182bd', 'DNAAeon-Low': '#6baed6',\n",
    "    'DNAFountain-High': '#006d2c', 'DNAFountain-Medium': '#31a354', 'DNAFountain-Low': '#74c476',\n",
    "    'DNARS-High': '#a63603', 'DNARS-Medium': '#e6550d', 'DNARS-Low': '#fd8d3c',\n",
    "    'HEDGES-Medium': '#756bb1', 'HEDGES-Low': '#9e9ac8',\n",
    "    'YinYang-High': '#636363', 'Goldman-Low': '#de2d26',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropout = data_dropout.get_fits_by_group(['codec.type', 'codec.name', 'workflow.name', 'workflow.type', 'workflow.dropout'], 'workflow.overall_rate', additional_agg={'code_rate': 'mean'})\n",
    "df_dropout['workflow.overall_rate'] = df_dropout['threshold']\n",
    "\n",
    "df_rate = data_rate.get_fits_by_group(['codec.type', 'codec.name', 'workflow.name', 'workflow.type', 'workflow.overall_rate'], 'workflow.dropout', additional_agg={'code_rate': 'mean'})\n",
    "df_rate['workflow.dropout'] = df_rate['threshold']\n",
    "\n",
    "df = pd.concat([df_dropout, df_rate], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://stackoverflow.com/questions/32791911/fast-calculation-of-pareto-front-in-python\n",
    "def is_pareto_optimal(costs):\n",
    "    is_efficient = np.all(np.logical_not(np.isnan(costs)), axis=1)\n",
    "    for i, c in enumerate(costs):\n",
    "        if is_efficient[i]:\n",
    "            is_efficient[is_efficient] = np.any(costs[is_efficient]<c, axis=1)  # Keep any point with a lower cost\n",
    "            is_efficient[i] = True  # And keep self\n",
    "    return is_efficient\n",
    "    \n",
    "# function that receives a groupby subset and only returns the pareto front\n",
    "def apply_pareto(group, cost1, cost2, cost1_max = False, cost2_max = False):\n",
    "    # get the costs\n",
    "    costs = group[[cost1, cost2]].values.astype(float)\n",
    "    # invert the costs if they are maximization problems\n",
    "    if cost1_max:\n",
    "        costs[:,0] = -costs[:,0]\n",
    "    if cost2_max:\n",
    "        costs[:,1] = -costs[:,1]\n",
    "    # get the pareto front\n",
    "    return group[is_pareto_optimal(costs)]\n",
    "\n",
    "# function that receives a groupby subset and returns the complete pareto front by adding extreme points if not present already\n",
    "def complete_pareto_front(group):\n",
    "    full = group.copy()\n",
    "    if full['workflow.overall_rate'].min() > 0.0001:\n",
    "        add = pd.DataFrame.from_dict({'codec.type': full['codec.type'].iloc[0], 'codec.name': full['codec.name'].iloc[0], 'workflow.type': full['workflow.type'].iloc[0], 'workflow.overall_rate': 0.0001, 'workflow.dropout': 1.001*full['workflow.dropout'].max()}, orient='index').T\n",
    "        full = pd.concat([full, add], ignore_index=True).reset_index(drop=True)\n",
    "    if full['workflow.dropout'].min() > 0.001:\n",
    "        add = pd.DataFrame.from_dict({'codec.type': full['codec.type'].iloc[0], 'codec.name': full['codec.name'].iloc[0], 'workflow.type': full['workflow.type'].iloc[0], 'workflow.overall_rate': 1.001*full['workflow.overall_rate'].max(), 'workflow.dropout': 0.001}, orient='index').T\n",
    "        full = pd.concat([full, add], ignore_index=True).reset_index(drop=True)\n",
    "    return full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = df.groupby(['codec.type', 'codec.name', 'workflow.type']).apply(apply_pareto, 'workflow.overall_rate', 'workflow.dropout', cost1_max = True, cost2_max = True, include_groups=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = idf.groupby(['codec.type', 'codec.name', 'workflow.type'])[['codec.type', 'codec.name', 'workflow.type', 'workflow.overall_rate', 'workflow.dropout']].apply(complete_pareto_front).reset_index(drop=True)\n",
    "\n",
    "plotdf = plotdf.sort_values(['codec.type', 'workflow.overall_rate', 'workflow.dropout'])\n",
    "plotdf['codec.name'] = plotdf['codec.name'].replace({'high': 'High', 'medium': 'Medium', 'low': 'Low', 'default': 'Low'})\n",
    "plotdf['name'] = plotdf['codec.type'] + '-' + plotdf['codec.name']\n",
    "plotdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    plotdf,\n",
    "    x='workflow.overall_rate', \n",
    "    y='workflow.dropout', \n",
    "    log_y=True, \n",
    "    # log_x=True, \n",
    "    color='codec.type',\n",
    "    facet_col='codec.name',\n",
    "    facet_col_spacing=0.08,\n",
    "    markers=True,\n",
    "    color_discrete_map=colormap_type,\n",
    "    category_orders={'codec.name': ['High', 'Medium', 'Low'],},\n",
    "    range_x=[0.0, 0.15],\n",
    "    range_y=[0.005, 1],\n",
    ")\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    width=340,\n",
    "    height=140,\n",
    "    margin=dict(l=0, r=10, t=20, b=0),\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=0.02,\n",
    "    line_dash='dot',\n",
    "    line_width=1,\n",
    "    row=1,\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=0.0065,\n",
    "    line_dash='dash',\n",
    "    line_width=1,\n",
    "    row=1,\n",
    ")\n",
    "fig.update_xaxes(dtick=0.05)\n",
    "fig.update_yaxes(dtick=1)\n",
    "fig.update_xaxes(title='Error rate per nt', tickformat=\",.0%\", row=1)\n",
    "fig.update_yaxes(title='Sequence dropout', tickformat=\",.0%\", col=1)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "\n",
    "fig = dt4dds_benchmark.analysis.plotting.standardize_plot(fig)\n",
    "fig.write_image('./figures/pareto_front.svg')\n",
    "fig.write_image('./figures/pareto_front.png', scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performancedf_dropout = pd.merge(data_dropout.combined_performances, data_dropout.results)\n",
    "performancedf_dropout = performancedf_dropout.drop(performancedf_dropout.loc[performancedf_dropout['decoding_success'] == False].index)\n",
    "performancedf_dropout = performancedf_dropout.drop(performancedf_dropout.loc[performancedf_dropout['identifier'] != b'decoding'].index)\n",
    "\n",
    "performancedf_rate = pd.merge(data_rate.combined_performances, data_rate.results)\n",
    "performancedf_rate = performancedf_rate.drop(performancedf_rate.loc[performancedf_rate['decoding_success'] == False].index)\n",
    "performancedf_rate = performancedf_rate.drop(performancedf_rate.loc[performancedf_rate['identifier'] != b'decoding'].index)\n",
    "\n",
    "performancedf = pd.concat([performancedf_dropout, performancedf_rate], ignore_index=True).reset_index()\n",
    "\n",
    "performancedf['codec.name'] = performancedf['codec.name'].map({\n",
    "    'default': '1low',\n",
    "    'low': '1low',\n",
    "    'medium': '2medium',\n",
    "    'high': '3high',\n",
    "})\n",
    "performancedf.loc[performancedf['codec.type'] == 'YinYang', 'codec.name'] = '3high'\n",
    "performancedf.sort_values(['codec.type', 'codec.name', 'duration'], inplace=True)\n",
    "performancedf['duration'] = performancedf['duration']/60\n",
    "\n",
    "performancedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    performancedf,\n",
    "    x='workflow.overall_rate',\n",
    "    y='workflow.dropout',\n",
    "    log_x=True,\n",
    "    log_y=True,\n",
    "    color='duration',\n",
    "    facet_col='codec.name',\n",
    "    facet_col_spacing=0.05,\n",
    "    facet_row='codec.type',\n",
    "    facet_row_spacing=0.03,\n",
    "    range_color=(0, 60),\n",
    "    color_continuous_scale='Inferno',\n",
    ")\n",
    "\n",
    "fig.for_each_xaxis(lambda xaxis: xaxis.update(range=[-3, 0], tickangle=0))\n",
    "fig.for_each_yaxis(lambda yaxis: yaxis.update(range=[-3, 0]))\n",
    "fig.update_xaxes(title='Error rate per nt', row=1)\n",
    "fig.update_xaxes(showticklabels=True, row=2)\n",
    "fig.update_yaxes(title='Sequence dropout', col=1)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_layout(\n",
    "    width=680,\n",
    "    height=800,\n",
    "    margin=dict(l=0, r=10, t=1, b=10),\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.update_coloraxes(colorbar={'orientation':'h', 'thickness': 20, 'y': 10.0})\n",
    "fig = dt4dds_benchmark.analysis.plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(f'./figures/runtime.svg')\n",
    "fig.write_image(f'./figures/runtime.png', scale=2)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
