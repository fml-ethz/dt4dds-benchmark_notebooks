{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dt4dds_benchmark\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = dt4dds_benchmark.analysis.Dataset.combine(*[dt4dds_benchmark.pipelines.HDF5Manager(f'./data/{w}/{s}.hdf5').get_data() for s in (\n",
    "    'aeon_high',\n",
    "    'aeon_low',\n",
    "    'aeon_medium',\n",
    "    'fountain_high',\n",
    "    'fountain_low',\n",
    "    'fountain_medium',\n",
    "    'goldman_default',\n",
    "    'rs_high',\n",
    "    'rs_low',\n",
    "    'rs_medium',\n",
    "    'hedges_low',\n",
    "    'hedges_medium',\n",
    "    'yinyang_default',\n",
    ") for w in (\n",
    "    'basic',\n",
    "    'cdhit',\n",
    "    'clover',\n",
    "    'lsh',\n",
    "    'mmseqs2',\n",
    "    'starcode',\n",
    ")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check fit of simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.separate_by_parameters(['codec.type', 'codec.name', 'clustering.name', 'clustering.type']):\n",
    "    c.fit('workflow.overall_rate').plot(title_columns=['codec.type', 'codec.name', 'clustering.name', 'clustering.type']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exemplary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = [data.only_with({'codec.type': 'DNAFountain', 'codec.name': 'high', 'clustering.type': cl}) for cl in ('BasicSet', 'CDHit')]\n",
    "\n",
    "exampledf = pd.concat([e.combined_results.copy() for e in example_data])\n",
    "exampledf['decoding_success'] = exampledf['decoding_success'].astype(float)\n",
    "\n",
    "examplefits = [c.fit('workflow.overall_rate') for c in example_data]\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    exampledf,\n",
    "    x='workflow.overall_rate',\n",
    "    y='decoding_success',\n",
    "    log_x=True,\n",
    "    color='clustering.type',\n",
    "    color_discrete_map={'BasicSet': '#969696', 'CDHit': '#fb6a4a'},\n",
    ")\n",
    "\n",
    "for fit in examplefits:\n",
    "    x_vals = np.logspace(-3, 0, 500)\n",
    "    y_vals = fit.predict(x_vals)\n",
    "    fig.add_scatter(\n",
    "        x=x_vals, \n",
    "        y=y_vals, \n",
    "        mode='lines', \n",
    "        line_color='#636363' if (fit.data['clustering.type'] == 'BasicSet').any() else '#de2d26',\n",
    "        line_width=2.5,\n",
    "    )\n",
    "    fig.add_vline(\n",
    "        x=fit.threshold,\n",
    "        line_dash='solid', \n",
    "        line_color='#636363' if (fit.data['clustering.type'] == 'BasicSet').any() else '#de2d26',\n",
    "        line_width=1,\n",
    "    )\n",
    "    print(fit.threshold)\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title='Error rate per nt',\n",
    "    range=[-2.4, -0.698],\n",
    "    dtick=1,\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title='Recovery probability',\n",
    "    tickformat=',.0%',\n",
    "    range=[-0.03, 1.03]\n",
    ")\n",
    "fig.add_hline(y=0.95, line_dash='dash', line_color='#252525', line_width=2)\n",
    "\n",
    "fig.add_vline(\n",
    "    x=examplefits[1].threshold,\n",
    "    line_dash='solid',\n",
    "    line_width=2,\n",
    "    line_color='#de2d26',\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=examplefits[0].threshold,\n",
    "    line_dash='solid',\n",
    "    line_width=2,\n",
    "    line_color='#252525',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=250,\n",
    "    height=130,\n",
    "    margin=dict(l=0, r=5, t=5, b=0),\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig = dt4dds_benchmark.analysis.plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "fig.write_image(f'./figures/example_fit.svg')\n",
    "fig.write_image(f'./figures/example_fit.png', scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the threshold values by codec, clustering, and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.get_fits_by_group(['codec.type', 'codec.name', 'clustering.name', 'clustering.type'], on='workflow.overall_rate', additional_agg={'code_rate': 'mean'})\n",
    "df['code_rate'] = df['code_rate'].map('{:.2f}'.format)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = df[['codec.type', 'code_rate', 'clustering.name', 'clustering.type', 'threshold']].copy()\n",
    "\n",
    "# convert to wide by codec name and type\n",
    "sdf = idf.pivot_table(columns=['clustering.type', 'clustering.name'], index=['codec.type', 'code_rate'], values='threshold', aggfunc='first').reset_index()\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot only best-performing clustering and the basic clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = df.loc[df['clustering.type'] != 'MMseqs2'].copy()\n",
    "plotdf['clustergroup'] = plotdf['clustering.type']\n",
    "idf = df.copy()\n",
    "idf['clustergroup'] = idf['clustering.type']\n",
    "\n",
    "# keep only rows where the threshold is highest per codec.type and codec.name, but always also include the BasicSet row\n",
    "plotdf = plotdf.loc[plotdf.groupby(['codec.type', 'codec.name'])['threshold'].idxmax()]\n",
    "plotdf['clustergroup'] = 'optimal'\n",
    "plotdf = pd.concat([plotdf, idf.loc[df['clustering.type'] == 'BasicSet']])\n",
    "plotdf['codec.type'] = plotdf['codec.type'].str.replace('Goldman', 'GM').replace('YinYang', 'YY')\n",
    "\n",
    "fig = dt4dds_benchmark.analysis.plotting.tiered_bar(\n",
    "    plotdf.sort_values(['codec.type', 'code_rate', 'clustering.type']),\n",
    "    \"codec.type\",\n",
    "    \"code_rate\",\n",
    "    \"threshold\",\n",
    "    color_by = \"clustergroup\",\n",
    "    color_discrete_map={'BasicSet': '#636363', 'optimal': '#31a354'},\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    range=[0, 0.15],\n",
    "    title='Error rate per nt',\n",
    "    # type=\"log\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=320,\n",
    "    height=140,\n",
    "    margin=dict(l=0, r=1, t=10, b=30),\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "\n",
    "fig = dt4dds_benchmark.analysis.plotting.standardize_plot(fig)\n",
    "fig.update_xaxes(\n",
    "    tickfont_size=28/3, \n",
    "    tickangle=0,\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image('./figures/best.svg')\n",
    "fig.write_image('./figures/best.png', scale=2)\n",
    "display(plotdf.sort_values(['codec.type', 'code_rate', 'clustering.type'])[['codec.type', 'codec.name', 'clustering.type', 'threshold', 'code_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the median improvement of clustering vs. BasicSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotdf = plotdf.copy()\n",
    "pivotdf['clustering.type'] = pivotdf['clustering.type'].str.replace('LSH', 'optimal').replace('CDHit', 'optimal').replace('Starcode', 'optimal')\n",
    "pivotdf = pivotdf.pivot_table(index=['codec.type', 'codec.name'], columns='clustering.type', values='threshold').reset_index()\n",
    "pivotdf['ratio'] = pivotdf['optimal'] / pivotdf['BasicSet']\n",
    "pivotdf['delta'] = pivotdf['optimal'] - pivotdf['BasicSet']\n",
    "\n",
    "pivotdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotdf['delta'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performancedf = pd.merge(data.combined_performances, data.results)\n",
    "# performancedf = performancedf.drop(performancedf.loc[performancedf['decoding_success'] == False].index)\n",
    "performancedf = performancedf.drop(performancedf.loc[performancedf['identifier'] != b'decoding'].index)\n",
    "performancedf['code_rate'] = performancedf['code_rate'].map('{:.2f}'.format)\n",
    "performancedf.loc[performancedf['code_rate'] == '1.51', 'code_rate'] = '1.50'\n",
    "performancedf.loc[performancedf['code_rate'] == '1.01', 'code_rate'] = '1.00'\n",
    "performancedf.loc[performancedf['clustering.type'] == 'BasicSet', 'clustering.type'] = 'Naive'\n",
    "\n",
    "performancedf['choosename'] = performancedf['codec.type'] + '_' + performancedf['codec.name'] + '_' + performancedf['clustering.type']\n",
    "plotdf = performancedf.loc[performancedf['choosename'].isin((\n",
    "    'DNAAeon_low_Naive',\n",
    "    'DNAAeon_low_CDHit',\n",
    "    'DNAAeon_medium_Naive',\n",
    "    'DNAAeon_medium_CDHit',\n",
    "    'DNAAeon_high_Naive',\n",
    "    'DNAAeon_high_CDHit',\n",
    "    'DNAFountain_low_Naive',\n",
    "    'DNAFountain_low_Starcode',\n",
    "    'DNAFountain_medium_Naive',\n",
    "    'DNAFountain_medium_Starcode',\n",
    "    'DNAFountain_high_Naive',\n",
    "    'DNAFountain_high_CDHit',\n",
    "    'DNARS_low_Naive',\n",
    "    'DNARS_low_CDHit',\n",
    "    'DNARS_medium_Naive',\n",
    "    'DNARS_medium_CDHit',\n",
    "    'DNARS_high_Naive',\n",
    "    'DNARS_high_CDHit',\n",
    "    'Goldman_default_Naive',\n",
    "    'Goldman_default_LSH',\n",
    "    'HEDGES_low_Naive',\n",
    "    'HEDGES_low_LSH',\n",
    "    'HEDGES_medium_Naive',\n",
    "    'HEDGES_medium_CDHit',\n",
    "    'YinYang_default_Naive',\n",
    "    'YinYang_default_CDHit',\n",
    "))].copy()\n",
    "plotdf.loc[plotdf['clustering.type'] != 'Naive', 'clustering.type'] = 'Clustering'\n",
    "plotdf['duration'] = plotdf['duration'] / 60\n",
    "plotdf.loc[plotdf['codec.type'] == 'Goldman', 'codec.name'] = 'low'\n",
    "plotdf.loc[plotdf['codec.type'] == 'YinYang', 'codec.name'] = 'high'\n",
    "\n",
    "# sort codec.name column to low, medium, high\n",
    "plotdf['codec.nameorder'] = plotdf['codec.name'].map({'low': 0, 'medium': 1, 'high': 2})\n",
    "plotdf = plotdf.sort_values(['codec.type', 'codec.nameorder'])\n",
    "\n",
    "plotdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    plotdf,\n",
    "    x='workflow.overall_rate',\n",
    "    y='duration',\n",
    "    color='codec.type',\n",
    "    facet_col='codec.name',\n",
    "    facet_row='clustering.type',\n",
    "    facet_row_spacing=0.1,\n",
    "    facet_col_spacing=0.05,\n",
    "    symbol='decoding_success',\n",
    "    color_discrete_map={'DNAAeon': '#3182bd', 'DNAFountain': '#31a354', 'DNARS': '#e6550d', 'HEDGES': '#756bb1', 'YinYang': '#636363', 'Goldman': '#de2d26'},\n",
    "    symbol_map={True: 'circle', False: 'circle-open'},\n",
    ")\n",
    "\n",
    "fig.add_hline(y=60, line_dash=\"dot\", line_color=\"black\", line_width=2)\n",
    "fig.update_xaxes(matches=None)\n",
    "fig.for_each_xaxis(lambda xaxis: xaxis.update(range=[0, 0.2], minor_dtick=0.025))\n",
    "fig.for_each_yaxis(lambda yaxis: yaxis.update(range=[0, 61], minor_dtick=10))\n",
    "fig.update_xaxes(title='Error rate per nt', row=1)\n",
    "fig.update_yaxes(title='Runtime / min', col=1)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_layout(\n",
    "    width=670,\n",
    "    height=300,\n",
    "    margin=dict(l=0, r=10, t=20, b=10),\n",
    "    showlegend=False,\n",
    ")\n",
    "fig = dt4dds_benchmark.analysis.plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "fig.write_image(f'./figures/duration.svg')\n",
    "fig.write_image(f'./figures/duration.png', scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    plotdf,\n",
    "    x='workflow.overall_rate',\n",
    "    y='memory_value',\n",
    "    color='codec.type',\n",
    "    facet_col='codec.name',\n",
    "    facet_row='clustering.type',\n",
    "    facet_row_spacing=0.1,\n",
    "    facet_col_spacing=0.05,\n",
    "    symbol='decoding_success',\n",
    "    color_discrete_map={'DNAAeon': '#3182bd', 'DNAFountain': '#31a354', 'DNARS': '#e6550d', 'HEDGES': '#756bb1', 'YinYang': '#636363', 'Goldman': '#de2d26'},\n",
    "    symbol_map={True: 'circle', False: 'circle-open'},\n",
    ")\n",
    "\n",
    "fig.add_hline(y=8, line_dash=\"dot\", line_color=\"black\", line_width=2)\n",
    "fig.update_xaxes(matches=None)\n",
    "fig.for_each_xaxis(lambda xaxis: xaxis.update(range=[0, 0.2], minor_dtick=0.025))\n",
    "fig.for_each_yaxis(lambda yaxis: yaxis.update(range=[0, 8.1], minor_dtick=1))\n",
    "fig.update_xaxes(title='Error rate per nt', row=1)\n",
    "fig.update_yaxes(title='Memory use / GB', col=1)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_layout(\n",
    "    width=670,\n",
    "    height=300,\n",
    "    margin=dict(l=0, r=10, t=20, b=10),\n",
    "    showlegend=False,\n",
    ")\n",
    "fig = dt4dds_benchmark.analysis.plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "fig.write_image(f'./figures/memory.svg')\n",
    "fig.write_image(f'./figures/memory.png', scale=2)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
